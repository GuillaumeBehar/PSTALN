2024-01-07 07:50:37,655 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,655 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)
  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=18, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2024-01-07 07:50:37,655 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,655 Corpus: 14450 train + 1476 dev + 416 test sentences
2024-01-07 07:50:37,656 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,656 Train:  14450 sentences
2024-01-07 07:50:37,656         (train_with_dev=False, train_with_test=False)
2024-01-07 07:50:37,656 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,656 Training Params:
2024-01-07 07:50:37,656  - learning_rate: "0.1" 
2024-01-07 07:50:37,656  - mini_batch_size: "32"
2024-01-07 07:50:37,656  - max_epochs: "1"
2024-01-07 07:50:37,656  - shuffle: "True"
2024-01-07 07:50:37,656 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,656 Plugins:
2024-01-07 07:50:37,656  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'
2024-01-07 07:50:37,656 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,657 Final evaluation on model from best epoch (best-model.pt)
2024-01-07 07:50:37,657  - metric: "('micro avg', 'f1-score')"
2024-01-07 07:50:37,657 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,657 Computation:
2024-01-07 07:50:37,657  - compute on device: cpu
2024-01-07 07:50:37,657  - embedding storage: cpu
2024-01-07 07:50:37,657 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,657 Model training base path: "saved_models\flair_embeddings"
2024-01-07 07:50:37,657 ----------------------------------------------------------------------------------------------------
2024-01-07 07:50:37,657 ----------------------------------------------------------------------------------------------------
2024-01-07 07:57:59,911 epoch 1 - iter 45/452 - loss 1.67255063 - time (sec): 442.24 - samples/sec: 78.76 - lr: 0.100000 - momentum: 0.000000
2024-01-07 08:05:42,629 epoch 1 - iter 90/452 - loss 1.26071551 - time (sec): 904.28 - samples/sec: 77.18 - lr: 0.100000 - momentum: 0.000000
2024-01-07 08:13:56,398 epoch 1 - iter 135/452 - loss 1.05455539 - time (sec): 1398.73 - samples/sec: 75.31 - lr: 0.100000 - momentum: 0.000000
